{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow2oM_NYc8bo",
        "outputId": "8a432a06-ef08-498e-89a7-ff2f549cd10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f9o2lWdnc-kE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B4Bce4pFb2jA"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Directory setup\n",
        "base_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "\n",
        "# Data transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((160, 160)),  # Slightly smaller than typical ResNet input\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((160, 160)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Loading datasets with PyTorch ImageFolder\n",
        "train_data = ImageFolder(root=base_dir, transform=data_transforms['train'])\n",
        "train_idx, val_idx = train_test_split(list(range(len(train_data))), test_size=0.2, random_state=42, stratify=train_data.targets)\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(train_data, batch_size=64, sampler=val_sampler, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Fc6HCjjP7W",
        "outputId": "c4d121b7-5ebb-4854-9867-c87f789f3fc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 189MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Model setup\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(train_data.classes))  # Replace the fully connected layer\n",
        "\n",
        "# Transfer model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DzdK5IhZjSgW"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % 20 == 19:  # Print every 20 mini-batches\n",
        "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 20:.4f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f'Training complete in {total_time // 60:.0f}m {total_time % 60:.0f}s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5EnFMqIqjWJ-"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the validation images: {100 * correct / total:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWlafBf9b5PB",
        "outputId": "ca2fb7c7-d9fc-44d0-ab31-68f910bb6b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 20, Loss: 2.4912\n",
            "Epoch 1, Batch 40, Loss: 1.7370\n",
            "Epoch 1, Batch 60, Loss: 1.5117\n",
            "Epoch 1, Batch 80, Loss: 1.4061\n",
            "Epoch 1, Batch 100, Loss: 1.3978\n",
            "Epoch 1, Batch 120, Loss: 1.3424\n",
            "Epoch 2, Batch 20, Loss: 1.0268\n",
            "Epoch 2, Batch 40, Loss: 1.0271\n",
            "Epoch 2, Batch 60, Loss: 0.9908\n",
            "Epoch 2, Batch 80, Loss: 0.9331\n",
            "Epoch 2, Batch 100, Loss: 0.9648\n",
            "Epoch 2, Batch 120, Loss: 1.0481\n",
            "Epoch 3, Batch 20, Loss: 0.7871\n",
            "Epoch 3, Batch 40, Loss: 0.7595\n",
            "Epoch 3, Batch 60, Loss: 0.7890\n",
            "Epoch 3, Batch 80, Loss: 0.7644\n",
            "Epoch 3, Batch 100, Loss: 0.8337\n",
            "Epoch 3, Batch 120, Loss: 0.7163\n",
            "Epoch 4, Batch 20, Loss: 0.5664\n",
            "Epoch 4, Batch 40, Loss: 0.5446\n",
            "Epoch 4, Batch 60, Loss: 0.6532\n",
            "Epoch 4, Batch 80, Loss: 0.6297\n",
            "Epoch 4, Batch 100, Loss: 0.6141\n",
            "Epoch 4, Batch 120, Loss: 0.5621\n",
            "Epoch 5, Batch 20, Loss: 0.5115\n",
            "Epoch 5, Batch 40, Loss: 0.4970\n",
            "Epoch 5, Batch 60, Loss: 0.4785\n",
            "Epoch 5, Batch 80, Loss: 0.4648\n",
            "Epoch 5, Batch 100, Loss: 0.5024\n",
            "Epoch 5, Batch 120, Loss: 0.4839\n",
            "Epoch 6, Batch 20, Loss: 0.3868\n",
            "Epoch 6, Batch 40, Loss: 0.3874\n",
            "Epoch 6, Batch 60, Loss: 0.3775\n",
            "Epoch 6, Batch 80, Loss: 0.4166\n",
            "Epoch 6, Batch 100, Loss: 0.4837\n",
            "Epoch 6, Batch 120, Loss: 0.5369\n",
            "Epoch 7, Batch 20, Loss: 0.4099\n",
            "Epoch 7, Batch 40, Loss: 0.3432\n",
            "Epoch 7, Batch 60, Loss: 0.3100\n",
            "Epoch 7, Batch 80, Loss: 0.3174\n",
            "Epoch 7, Batch 100, Loss: 0.3941\n",
            "Epoch 7, Batch 120, Loss: 0.3698\n",
            "Epoch 8, Batch 20, Loss: 0.2229\n",
            "Epoch 8, Batch 40, Loss: 0.2049\n",
            "Epoch 8, Batch 60, Loss: 0.1856\n",
            "Epoch 8, Batch 80, Loss: 0.1287\n",
            "Epoch 8, Batch 100, Loss: 0.1416\n",
            "Epoch 8, Batch 120, Loss: 0.1423\n",
            "Epoch 9, Batch 20, Loss: 0.1071\n",
            "Epoch 9, Batch 40, Loss: 0.0909\n",
            "Epoch 9, Batch 60, Loss: 0.1112\n",
            "Epoch 9, Batch 80, Loss: 0.0899\n",
            "Epoch 9, Batch 100, Loss: 0.0862\n",
            "Epoch 9, Batch 120, Loss: 0.0710\n",
            "Epoch 10, Batch 20, Loss: 0.0636\n",
            "Epoch 10, Batch 40, Loss: 0.0706\n",
            "Epoch 10, Batch 60, Loss: 0.0667\n",
            "Epoch 10, Batch 80, Loss: 0.0622\n",
            "Epoch 10, Batch 100, Loss: 0.0729\n",
            "Epoch 10, Batch 120, Loss: 0.0639\n",
            "Training complete in 18m 33s\n",
            "Accuracy of the model on the validation images: 78.44%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training and evaluation\n",
        "train_model(model, criterion, optimizer, scheduler, num_epochs=10)\n",
        "evaluate_model(model, val_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
