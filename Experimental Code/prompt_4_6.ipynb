{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqAXNHw4m2X",
        "outputId": "49ee1681-9751-49af-cc03-ced6f0f5babd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tv2GNRNk4NjR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torch import nn, optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import os\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h1f1YgkP5TpT"
      },
      "outputs": [],
      "source": [
        "# Data loading and transformation setup\n",
        "def load_data(data_dir):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    full_dataset = ImageFolder(root=data_dir)\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "    train_dataset.dataset.transform = transform_train\n",
        "    test_dataset.dataset.transform = transform_test\n",
        "\n",
        "    class_counts = np.bincount([full_dataset.targets[i] for i in train_dataset.indices])\n",
        "    class_weights = 1. / (class_counts + 1e-6)\n",
        "    sample_weights = class_weights[[full_dataset.targets[i] for i in train_dataset.indices]]\n",
        "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "    return train_dataset, test_dataset, sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6KvF_8Ur5Xci"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "def create_model(num_classes):\n",
        "    model = resnet50(pretrained=True)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IWhpqLV05cs4"
      },
      "outputs": [],
      "source": [
        "# Model training with mixed precision\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
        "    model.to(device)\n",
        "    scaler = GradScaler()\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Step {i}, Loss: {loss.item()}')\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f'Training time for epoch {epoch+1}: {elapsed_time:.2f} seconds')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eXzPn7LXio2r"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "def evaluate_model(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on test set: {accuracy}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20u7yRO8nWs",
        "outputId": "9d13957b-a9e3-475c-93d8-33ea35257752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Step 0, Loss: 4.14190673828125\n",
            "Epoch 1/10, Step 20, Loss: 3.1257553100585938\n",
            "Epoch 1/10, Step 40, Loss: 2.7007944583892822\n",
            "Epoch 1/10, Step 60, Loss: 2.3544106483459473\n",
            "Epoch 1/10, Step 80, Loss: 2.5450572967529297\n",
            "Epoch 1/10, Step 100, Loss: 2.5978689193725586\n",
            "Epoch 1/10, Step 120, Loss: 2.2019705772399902\n",
            "Training time for epoch 1: 80.00 seconds\n",
            "Epoch 2/10, Step 0, Loss: 1.7251014709472656\n",
            "Epoch 2/10, Step 20, Loss: 1.8758130073547363\n",
            "Epoch 2/10, Step 40, Loss: 1.6479625701904297\n",
            "Epoch 2/10, Step 60, Loss: 1.8215947151184082\n",
            "Epoch 2/10, Step 80, Loss: 1.5668410062789917\n",
            "Epoch 2/10, Step 100, Loss: 1.445160150527954\n",
            "Epoch 2/10, Step 120, Loss: 1.4572689533233643\n",
            "Training time for epoch 2: 50.74 seconds\n",
            "Epoch 3/10, Step 0, Loss: 1.58429753780365\n",
            "Epoch 3/10, Step 20, Loss: 1.4516232013702393\n",
            "Epoch 3/10, Step 40, Loss: 1.45829176902771\n",
            "Epoch 3/10, Step 60, Loss: 1.49888014793396\n",
            "Epoch 3/10, Step 80, Loss: 1.246508240699768\n",
            "Epoch 3/10, Step 100, Loss: 1.0307159423828125\n",
            "Epoch 3/10, Step 120, Loss: 0.9830180406570435\n",
            "Training time for epoch 3: 36.93 seconds\n",
            "Epoch 4/10, Step 0, Loss: 1.0512669086456299\n",
            "Epoch 4/10, Step 20, Loss: 1.3377338647842407\n",
            "Epoch 4/10, Step 40, Loss: 1.256561279296875\n",
            "Epoch 4/10, Step 60, Loss: 1.2738534212112427\n",
            "Epoch 4/10, Step 80, Loss: 0.8908261656761169\n",
            "Epoch 4/10, Step 100, Loss: 1.645005464553833\n",
            "Epoch 4/10, Step 120, Loss: 1.1518621444702148\n",
            "Training time for epoch 4: 33.05 seconds\n",
            "Epoch 5/10, Step 0, Loss: 1.3383612632751465\n",
            "Epoch 5/10, Step 20, Loss: 0.8625205159187317\n",
            "Epoch 5/10, Step 40, Loss: 1.014106035232544\n",
            "Epoch 5/10, Step 60, Loss: 0.8416177034378052\n",
            "Epoch 5/10, Step 80, Loss: 0.9646778702735901\n",
            "Epoch 5/10, Step 100, Loss: 0.8424426317214966\n",
            "Epoch 5/10, Step 120, Loss: 0.8711601495742798\n",
            "Training time for epoch 5: 32.12 seconds\n",
            "Epoch 6/10, Step 0, Loss: 0.8090133666992188\n",
            "Epoch 6/10, Step 20, Loss: 1.053415060043335\n",
            "Epoch 6/10, Step 40, Loss: 0.7322584390640259\n",
            "Epoch 6/10, Step 60, Loss: 1.0729475021362305\n",
            "Epoch 6/10, Step 80, Loss: 0.8572638034820557\n",
            "Epoch 6/10, Step 100, Loss: 0.8147232532501221\n",
            "Epoch 6/10, Step 120, Loss: 0.5305179953575134\n",
            "Training time for epoch 6: 30.70 seconds\n",
            "Epoch 7/10, Step 0, Loss: 0.5768347382545471\n",
            "Epoch 7/10, Step 20, Loss: 0.36174315214157104\n",
            "Epoch 7/10, Step 40, Loss: 0.6950446367263794\n",
            "Epoch 7/10, Step 60, Loss: 0.541904628276825\n",
            "Epoch 7/10, Step 80, Loss: 0.43217483162879944\n",
            "Epoch 7/10, Step 100, Loss: 0.5142979621887207\n",
            "Epoch 7/10, Step 120, Loss: 0.8570099472999573\n",
            "Training time for epoch 7: 30.32 seconds\n",
            "Epoch 8/10, Step 0, Loss: 0.49320048093795776\n",
            "Epoch 8/10, Step 20, Loss: 0.5825566649436951\n",
            "Epoch 8/10, Step 40, Loss: 0.44440269470214844\n",
            "Epoch 8/10, Step 60, Loss: 0.6254783272743225\n",
            "Epoch 8/10, Step 80, Loss: 0.4622674286365509\n",
            "Epoch 8/10, Step 100, Loss: 0.3996866047382355\n",
            "Epoch 8/10, Step 120, Loss: 0.6626900434494019\n",
            "Training time for epoch 8: 29.92 seconds\n",
            "Epoch 9/10, Step 0, Loss: 0.3066118061542511\n",
            "Epoch 9/10, Step 20, Loss: 0.4927535653114319\n",
            "Epoch 9/10, Step 40, Loss: 0.5372181534767151\n",
            "Epoch 9/10, Step 60, Loss: 0.3320005536079407\n",
            "Epoch 9/10, Step 80, Loss: 0.6106572151184082\n",
            "Epoch 9/10, Step 100, Loss: 0.4706876873970032\n",
            "Epoch 9/10, Step 120, Loss: 0.3856744170188904\n",
            "Training time for epoch 9: 30.09 seconds\n",
            "Epoch 10/10, Step 0, Loss: 0.2706601023674011\n",
            "Epoch 10/10, Step 20, Loss: 0.3210785984992981\n",
            "Epoch 10/10, Step 40, Loss: 0.43205195665359497\n",
            "Epoch 10/10, Step 60, Loss: 0.386987566947937\n",
            "Epoch 10/10, Step 80, Loss: 0.25049710273742676\n",
            "Epoch 10/10, Step 100, Loss: 0.27686095237731934\n",
            "Epoch 10/10, Step 120, Loss: 0.21246391534805298\n",
            "Training time for epoch 10: 29.98 seconds\n",
            "Accuracy on test set: 64.88586692569208%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "    train_dataset, test_dataset, sampler = load_data(data_dir)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler, num_workers=8, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    model = create_model(num_classes=len(train_dataset.dataset.classes))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_model(model, train_loader, criterion, optimizer)\n",
        "    evaluate_model(model, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
