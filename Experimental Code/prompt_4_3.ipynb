{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow2oM_NYc8bo",
        "outputId": "21d164fb-edc6-4709-e200-2a4445c1df73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f9o2lWdnc-kE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split\n",
        "from torch.optim import Adam\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NTy6ULjhdXtV"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir, batch_size):\n",
        "    # Define transformations\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Load dataset\n",
        "    full_dataset = ImageFolder(root=data_dir)\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    # Apply transformations appropriately\n",
        "    train_dataset.dataset = ImageFolder(root=data_dir, transform=transform_train)\n",
        "    test_dataset.dataset = ImageFolder(root=data_dir, transform=transform_test)\n",
        "\n",
        "    # Efficient calculation of class weights using tensor operations\n",
        "    target_list = torch.tensor([y for _, y in train_dataset.dataset.samples])\n",
        "    class_counts = torch.bincount(target_list[train_dataset.indices])\n",
        "    class_weights = 1.0 / (class_counts.float() + 1e-6)\n",
        "    sample_weights = class_weights[target_list[train_dataset.indices]]\n",
        "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=8, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6SVYIdBYHKzz"
      },
      "outputs": [],
      "source": [
        "def define_model(num_classes):\n",
        "    # Modify the pretrained ResNet50 model\n",
        "    model = resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_ftrs, num_classes),\n",
        "        nn.BatchNorm1d(num_classes)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "ulGfQfUWdlHv"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "def train_model(model, train_loader, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f'Epoch {epoch+1}, Step {i}, Loss: {loss.item()}')\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        print(f'Epoch {epoch+1} completed in {epoch_time:.2f} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FOJZbeIidqPi"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Iq0tLSdyKS",
        "outputId": "14c137ae-631c-4a89-d0a6-bf2c1a14e88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 0, Loss: 4.416748046875\n",
            "Epoch 1, Step 20, Loss: 2.3235626220703125\n",
            "Epoch 1, Step 40, Loss: 2.0426712036132812\n",
            "Epoch 1, Step 60, Loss: 2.008150100708008\n",
            "Epoch 1, Step 80, Loss: 1.734346866607666\n",
            "Epoch 1, Step 100, Loss: 1.4771003723144531\n",
            "Epoch 1, Step 120, Loss: 1.4335107803344727\n",
            "Epoch 1 completed in 29.32 seconds\n",
            "Epoch 2, Step 0, Loss: 1.5796875953674316\n",
            "Epoch 2, Step 20, Loss: 1.6311328411102295\n",
            "Epoch 2, Step 40, Loss: 1.6092958450317383\n",
            "Epoch 2, Step 60, Loss: 1.7608165740966797\n",
            "Epoch 2, Step 80, Loss: 1.1521098613739014\n",
            "Epoch 2, Step 100, Loss: 1.4092659950256348\n",
            "Epoch 2, Step 120, Loss: 1.2599318027496338\n",
            "Epoch 2 completed in 29.11 seconds\n",
            "Epoch 3, Step 0, Loss: 1.2696633338928223\n",
            "Epoch 3, Step 20, Loss: 1.377254843711853\n",
            "Epoch 3, Step 40, Loss: 1.1072807312011719\n",
            "Epoch 3, Step 60, Loss: 1.297135829925537\n",
            "Epoch 3, Step 80, Loss: 1.345583200454712\n",
            "Epoch 3, Step 100, Loss: 1.0745306015014648\n",
            "Epoch 3, Step 120, Loss: 1.0636987686157227\n",
            "Epoch 3 completed in 30.15 seconds\n",
            "Epoch 4, Step 0, Loss: 1.1672744750976562\n",
            "Epoch 4, Step 20, Loss: 0.9126856327056885\n",
            "Epoch 4, Step 40, Loss: 1.0819573402404785\n",
            "Epoch 4, Step 60, Loss: 1.0860927104949951\n",
            "Epoch 4, Step 80, Loss: 0.8730971813201904\n",
            "Epoch 4, Step 100, Loss: 1.1701322793960571\n",
            "Epoch 4, Step 120, Loss: 1.2024222612380981\n",
            "Epoch 4 completed in 29.12 seconds\n",
            "Epoch 5, Step 0, Loss: 1.090153694152832\n",
            "Epoch 5, Step 20, Loss: 0.8839578628540039\n",
            "Epoch 5, Step 40, Loss: 0.8743294477462769\n",
            "Epoch 5, Step 60, Loss: 0.9292471408843994\n",
            "Epoch 5, Step 80, Loss: 0.9493508338928223\n",
            "Epoch 5, Step 100, Loss: 0.8106433153152466\n",
            "Epoch 5, Step 120, Loss: 0.845585823059082\n",
            "Epoch 5 completed in 29.10 seconds\n",
            "Epoch 6, Step 0, Loss: 1.0027178525924683\n",
            "Epoch 6, Step 20, Loss: 0.9766037464141846\n",
            "Epoch 6, Step 40, Loss: 1.0277332067489624\n",
            "Epoch 6, Step 60, Loss: 0.7544957995414734\n",
            "Epoch 6, Step 80, Loss: 1.0578079223632812\n",
            "Epoch 6, Step 100, Loss: 0.6293113231658936\n",
            "Epoch 6, Step 120, Loss: 0.8184036016464233\n",
            "Epoch 6 completed in 29.29 seconds\n",
            "Epoch 7, Step 0, Loss: 0.816556453704834\n",
            "Epoch 7, Step 20, Loss: 1.0408920049667358\n",
            "Epoch 7, Step 40, Loss: 0.7617138624191284\n",
            "Epoch 7, Step 60, Loss: 0.878322184085846\n",
            "Epoch 7, Step 80, Loss: 0.8764817714691162\n",
            "Epoch 7, Step 100, Loss: 0.7139565944671631\n",
            "Epoch 7, Step 120, Loss: 0.8886643648147583\n",
            "Epoch 7 completed in 28.86 seconds\n",
            "Epoch 8, Step 0, Loss: 0.7671678066253662\n",
            "Epoch 8, Step 20, Loss: 0.7127076387405396\n",
            "Epoch 8, Step 40, Loss: 0.9664480090141296\n",
            "Epoch 8, Step 60, Loss: 0.6467747688293457\n",
            "Epoch 8, Step 80, Loss: 0.722623348236084\n",
            "Epoch 8, Step 100, Loss: 0.7974625825881958\n",
            "Epoch 8, Step 120, Loss: 0.412850558757782\n",
            "Epoch 8 completed in 29.12 seconds\n",
            "Epoch 9, Step 0, Loss: 0.5884339809417725\n",
            "Epoch 9, Step 20, Loss: 0.7825931906700134\n",
            "Epoch 9, Step 40, Loss: 0.553828239440918\n",
            "Epoch 9, Step 60, Loss: 0.6389502286911011\n",
            "Epoch 9, Step 80, Loss: 0.6401774883270264\n",
            "Epoch 9, Step 100, Loss: 0.6131076216697693\n",
            "Epoch 9, Step 120, Loss: 0.751232385635376\n",
            "Epoch 9 completed in 29.15 seconds\n",
            "Epoch 10, Step 0, Loss: 0.7266510725021362\n",
            "Epoch 10, Step 20, Loss: 0.47289496660232544\n",
            "Epoch 10, Step 40, Loss: 0.5614060759544373\n",
            "Epoch 10, Step 60, Loss: 0.42217981815338135\n",
            "Epoch 10, Step 80, Loss: 0.7959631085395813\n",
            "Epoch 10, Step 100, Loss: 0.5884575843811035\n",
            "Epoch 10, Step 120, Loss: 0.7545533180236816\n",
            "Epoch 10 completed in 29.08 seconds\n",
            "Test Accuracy: 69.50%\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    data_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "    batch_size = 64\n",
        "    num_classes = 50\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_loader, test_loader = load_data(data_dir, batch_size)\n",
        "    model = define_model(num_classes)\n",
        "    train_model(model, train_loader, device)\n",
        "    evaluate_model(model, test_loader, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
