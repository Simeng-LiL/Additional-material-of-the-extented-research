{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqAXNHw4m2X",
        "outputId": "90c8f366-b33f-4a17-fa69-b256d25dc267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tv2GNRNk4NjR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet34\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mRs8MKIj8kqX"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "data_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "batch_size = 32\n",
        "num_workers = 4\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "print_step = 20  # Print loss every 20 steps\n",
        "\n",
        "# 1. Data Loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "dataset = ImageFolder(root=data_dir, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S20u7yRO8nWs"
      },
      "outputs": [],
      "source": [
        "# 2. Model Setup\n",
        "model = resnet34(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 50)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "torch.backends.cudnn.benchmark = True  # Enable cuDNN auto-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_tBw5vv8qG7",
        "outputId": "8d0cd321-39bc-4a25-ddb0-af2824cff486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 20, Loss: 2.2346882820129395\n",
            "Epoch 1, Step 40, Loss: 2.900305986404419\n",
            "Epoch 1, Step 60, Loss: 3.0036957263946533\n",
            "Epoch 1, Step 80, Loss: 2.186126947402954\n",
            "Epoch 1, Step 100, Loss: 2.0259175300598145\n",
            "Epoch 1, Step 120, Loss: 1.6902984380722046\n",
            "Epoch 1, Step 140, Loss: 1.867910623550415\n",
            "Epoch 1, Step 160, Loss: 1.8519620895385742\n",
            "Epoch 1, Step 180, Loss: 1.5505088567733765\n",
            "Epoch 1, Step 200, Loss: 1.2665947675704956\n",
            "Epoch 1, Step 220, Loss: 1.7678723335266113\n",
            "Epoch 1, Step 240, Loss: 2.639819860458374\n",
            "Epoch 1 completed in 1473.16 seconds, Average Loss: 2.166012548198996\n",
            "Epoch 2, Step 20, Loss: 1.5490702390670776\n",
            "Epoch 2, Step 40, Loss: 1.4684022665023804\n",
            "Epoch 2, Step 60, Loss: 1.3083747625350952\n",
            "Epoch 2, Step 80, Loss: 0.9680299162864685\n",
            "Epoch 2, Step 100, Loss: 1.9287347793579102\n",
            "Epoch 2, Step 120, Loss: 1.027632474899292\n",
            "Epoch 2, Step 140, Loss: 1.0551236867904663\n",
            "Epoch 2, Step 160, Loss: 0.746101975440979\n",
            "Epoch 2, Step 180, Loss: 1.2534312009811401\n",
            "Epoch 2, Step 200, Loss: 1.7045739889144897\n",
            "Epoch 2, Step 220, Loss: 1.0630377531051636\n",
            "Epoch 2, Step 240, Loss: 1.0210919380187988\n",
            "Epoch 2 completed in 38.86 seconds, Average Loss: 1.3213463735210804\n",
            "Epoch 3, Step 20, Loss: 0.9557235240936279\n",
            "Epoch 3, Step 40, Loss: 0.7095485925674438\n",
            "Epoch 3, Step 60, Loss: 0.6763017177581787\n",
            "Epoch 3, Step 80, Loss: 0.8096030950546265\n",
            "Epoch 3, Step 100, Loss: 0.9431614279747009\n",
            "Epoch 3, Step 120, Loss: 1.2024165391921997\n",
            "Epoch 3, Step 140, Loss: 0.7977165579795837\n",
            "Epoch 3, Step 160, Loss: 0.6178345084190369\n",
            "Epoch 3, Step 180, Loss: 1.106151819229126\n",
            "Epoch 3, Step 200, Loss: 0.505703866481781\n",
            "Epoch 3, Step 220, Loss: 1.1472047567367554\n",
            "Epoch 3, Step 240, Loss: 1.4550962448120117\n",
            "Epoch 3 completed in 39.22 seconds, Average Loss: 0.9719926657140717\n",
            "Epoch 4, Step 20, Loss: 0.5341812372207642\n",
            "Epoch 4, Step 40, Loss: 0.6980190277099609\n",
            "Epoch 4, Step 60, Loss: 0.6446152329444885\n",
            "Epoch 4, Step 80, Loss: 0.5581341981887817\n",
            "Epoch 4, Step 100, Loss: 0.5472176671028137\n",
            "Epoch 4, Step 120, Loss: 0.5093569159507751\n",
            "Epoch 4, Step 140, Loss: 0.7078815698623657\n",
            "Epoch 4, Step 160, Loss: 0.7714825868606567\n",
            "Epoch 4, Step 180, Loss: 0.8014928102493286\n",
            "Epoch 4, Step 200, Loss: 0.8043900728225708\n",
            "Epoch 4, Step 220, Loss: 0.9261595606803894\n",
            "Epoch 4, Step 240, Loss: 0.7328465580940247\n",
            "Epoch 4 completed in 39.37 seconds, Average Loss: 0.6778949629659801\n",
            "Epoch 5, Step 20, Loss: 0.6272458434104919\n",
            "Epoch 5, Step 40, Loss: 0.3325628340244293\n",
            "Epoch 5, Step 60, Loss: 0.5005002021789551\n",
            "Epoch 5, Step 80, Loss: 0.3785715699195862\n",
            "Epoch 5, Step 100, Loss: 0.41873928904533386\n",
            "Epoch 5, Step 120, Loss: 0.2622569799423218\n",
            "Epoch 5, Step 140, Loss: 0.8459599614143372\n",
            "Epoch 5, Step 160, Loss: 0.9652491211891174\n",
            "Epoch 5, Step 180, Loss: 0.6909803748130798\n",
            "Epoch 5, Step 200, Loss: 0.637418270111084\n",
            "Epoch 5, Step 220, Loss: 0.43123552203178406\n",
            "Epoch 5, Step 240, Loss: 0.3377704620361328\n",
            "Epoch 5 completed in 39.33 seconds, Average Loss: 0.5429378596040629\n",
            "Epoch 6, Step 20, Loss: 0.44495686888694763\n",
            "Epoch 6, Step 40, Loss: 0.5147972106933594\n",
            "Epoch 6, Step 60, Loss: 0.18149742484092712\n",
            "Epoch 6, Step 80, Loss: 0.32886311411857605\n",
            "Epoch 6, Step 100, Loss: 0.4767064154148102\n",
            "Epoch 6, Step 120, Loss: 0.33710789680480957\n",
            "Epoch 6, Step 140, Loss: 0.43273991346359253\n",
            "Epoch 6, Step 160, Loss: 0.39172860980033875\n",
            "Epoch 6, Step 180, Loss: 0.27807116508483887\n",
            "Epoch 6, Step 200, Loss: 0.4825510084629059\n",
            "Epoch 6, Step 220, Loss: 0.5409226417541504\n",
            "Epoch 6, Step 240, Loss: 0.3516108989715576\n",
            "Epoch 6 completed in 39.35 seconds, Average Loss: 0.41074335468254347\n",
            "Epoch 7, Step 20, Loss: 0.7312977313995361\n",
            "Epoch 7, Step 40, Loss: 0.16257640719413757\n",
            "Epoch 7, Step 60, Loss: 0.36809539794921875\n",
            "Epoch 7, Step 80, Loss: 0.5248705744743347\n",
            "Epoch 7, Step 100, Loss: 0.2106054127216339\n",
            "Epoch 7, Step 120, Loss: 0.2659481465816498\n",
            "Epoch 7, Step 140, Loss: 0.14747725427150726\n",
            "Epoch 7, Step 160, Loss: 0.2015172690153122\n",
            "Epoch 7, Step 180, Loss: 0.2041260004043579\n",
            "Epoch 7, Step 200, Loss: 0.0952046662569046\n",
            "Epoch 7, Step 220, Loss: 0.46186473965644836\n",
            "Epoch 7, Step 240, Loss: 0.3331696689128876\n",
            "Epoch 7 completed in 39.64 seconds, Average Loss: 0.2946643048767434\n",
            "Epoch 8, Step 20, Loss: 0.27555903792381287\n",
            "Epoch 8, Step 40, Loss: 0.24745287001132965\n",
            "Epoch 8, Step 60, Loss: 0.3974490463733673\n",
            "Epoch 8, Step 80, Loss: 0.1258011758327484\n",
            "Epoch 8, Step 100, Loss: 0.10761284083127975\n",
            "Epoch 8, Step 120, Loss: 0.3229551315307617\n",
            "Epoch 8, Step 140, Loss: 0.21209825575351715\n",
            "Epoch 8, Step 160, Loss: 0.33630236983299255\n",
            "Epoch 8, Step 180, Loss: 0.17288419604301453\n",
            "Epoch 8, Step 200, Loss: 0.4002677798271179\n",
            "Epoch 8, Step 220, Loss: 0.4116024971008301\n",
            "Epoch 8, Step 240, Loss: 0.26804879307746887\n",
            "Epoch 8 completed in 39.62 seconds, Average Loss: 0.24909104639303314\n",
            "Epoch 9, Step 20, Loss: 0.22618559002876282\n",
            "Epoch 9, Step 40, Loss: 0.29073020815849304\n",
            "Epoch 9, Step 60, Loss: 0.08790606260299683\n",
            "Epoch 9, Step 80, Loss: 0.20587565004825592\n",
            "Epoch 9, Step 100, Loss: 0.3835630714893341\n",
            "Epoch 9, Step 120, Loss: 0.0771319642663002\n",
            "Epoch 9, Step 140, Loss: 0.5760180950164795\n",
            "Epoch 9, Step 160, Loss: 0.10545184463262558\n",
            "Epoch 9, Step 180, Loss: 0.3189607560634613\n",
            "Epoch 9, Step 200, Loss: 0.3555774688720703\n",
            "Epoch 9, Step 220, Loss: 0.16077075898647308\n",
            "Epoch 9, Step 240, Loss: 0.45064017176628113\n",
            "Epoch 9 completed in 39.13 seconds, Average Loss: 0.21207417153515096\n",
            "Epoch 10, Step 20, Loss: 0.07218987494707108\n",
            "Epoch 10, Step 40, Loss: 0.38927996158599854\n",
            "Epoch 10, Step 60, Loss: 0.1174292340874672\n",
            "Epoch 10, Step 80, Loss: 0.13723470270633698\n",
            "Epoch 10, Step 100, Loss: 0.4824816882610321\n",
            "Epoch 10, Step 120, Loss: 0.25145941972732544\n",
            "Epoch 10, Step 140, Loss: 0.3332148492336273\n",
            "Epoch 10, Step 160, Loss: 0.32311055064201355\n",
            "Epoch 10, Step 180, Loss: 0.1758202165365219\n",
            "Epoch 10, Step 200, Loss: 0.037511009722948074\n",
            "Epoch 10, Step 220, Loss: 0.04484707862138748\n",
            "Epoch 10, Step 240, Loss: 0.17066898941993713\n",
            "Epoch 10 completed in 38.89 seconds, Average Loss: 0.21404755123450545\n"
          ]
        }
      ],
      "source": [
        "# 3. Model Training\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()  # Start timing for the epoch\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print every 20 steps\n",
        "        if (i + 1) % print_step == 0:\n",
        "            print(f'Epoch {epoch+1}, Step {i+1}, Loss: {loss.item()}')\n",
        "\n",
        "    end_time = time.time()  # End timing for the epoch\n",
        "    epoch_duration = end_time - start_time\n",
        "    print(f'Epoch {epoch+1} completed in {epoch_duration:.2f} seconds, Average Loss: {running_loss / len(train_loader)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amt-MA7MowQM",
        "outputId": "b5b1c6f7-165e-40b5-c62a-675d1b7d9adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 65.56580864497329%\n"
          ]
        }
      ],
      "source": [
        "# 4. Model Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: {100 * correct / total}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
