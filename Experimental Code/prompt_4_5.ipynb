{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqAXNHw4m2X",
        "outputId": "a4d3b6c8-6fa2-48f9-8392-8cb40ae4b48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tv2GNRNk4NjR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam\n",
        "from torch.cuda.amp import GradScaler, autocast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "XUsfKwfVlypt"
      },
      "outputs": [],
      "source": [
        "# Data loading and preprocessing\n",
        "def load_data(data_dir, batch_size, num_workers):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    full_dataset = ImageFolder(data_dir)\n",
        "    train_idx, test_idx = train_test_split(list(range(len(full_dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "    train_data = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "    test_data = torch.utils.data.Subset(full_dataset, test_idx)\n",
        "\n",
        "    # Apply transforms\n",
        "    train_data.dataset.transform = transform_train\n",
        "    test_data.dataset.transform = transform_test\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_counts = [0] * 50\n",
        "    for idx in train_idx:\n",
        "        class_counts[full_dataset.targets[idx]] += 1\n",
        "    class_weights = 1. / torch.tensor([x + 1e-6 for x in class_counts], dtype=torch.float)\n",
        "    sample_weights = [class_weights[target] for target in full_dataset.targets if target in train_idx]\n",
        "\n",
        "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "7197R5Wpl1Pb"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "def create_model(num_classes):\n",
        "    model = resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = torch.nn.Sequential(\n",
        "        torch.nn.BatchNorm1d(num_ftrs),\n",
        "        torch.nn.Dropout(0.5),\n",
        "        torch.nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rl_9o-3ql4Qi"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(model, train_loader, device, epochs=10, lr=0.001):\n",
        "    model = model.to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    scaler = GradScaler()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training completed in {training_time:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Ifgr3isBl6UC"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Test Accuracy: {:.2f}%'.format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icakLSqPZ26c",
        "outputId": "39ece7cf-a29e-4f4d-9d25-cc32e9d5d5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [20/115], Loss: 2.8278\n",
            "Epoch [1/10], Step [40/115], Loss: 2.1973\n",
            "Epoch [1/10], Step [60/115], Loss: 1.7469\n",
            "Epoch [1/10], Step [80/115], Loss: 1.4204\n",
            "Epoch [1/10], Step [100/115], Loss: 1.6971\n",
            "Epoch [2/10], Step [20/115], Loss: 1.3126\n",
            "Epoch [2/10], Step [40/115], Loss: 1.1029\n",
            "Epoch [2/10], Step [60/115], Loss: 1.0474\n",
            "Epoch [2/10], Step [80/115], Loss: 0.8008\n",
            "Epoch [2/10], Step [100/115], Loss: 1.3350\n",
            "Epoch [3/10], Step [20/115], Loss: 0.8101\n",
            "Epoch [3/10], Step [40/115], Loss: 0.9621\n",
            "Epoch [3/10], Step [60/115], Loss: 0.6383\n",
            "Epoch [3/10], Step [80/115], Loss: 0.6198\n",
            "Epoch [3/10], Step [100/115], Loss: 0.4094\n",
            "Epoch [4/10], Step [20/115], Loss: 0.7007\n",
            "Epoch [4/10], Step [40/115], Loss: 0.5796\n",
            "Epoch [4/10], Step [60/115], Loss: 0.4829\n",
            "Epoch [4/10], Step [80/115], Loss: 0.6087\n",
            "Epoch [4/10], Step [100/115], Loss: 0.7161\n",
            "Epoch [5/10], Step [20/115], Loss: 0.7859\n",
            "Epoch [5/10], Step [40/115], Loss: 0.5852\n",
            "Epoch [5/10], Step [60/115], Loss: 0.6573\n",
            "Epoch [5/10], Step [80/115], Loss: 0.8781\n",
            "Epoch [5/10], Step [100/115], Loss: 0.4433\n",
            "Epoch [6/10], Step [20/115], Loss: 0.6772\n",
            "Epoch [6/10], Step [40/115], Loss: 0.4996\n",
            "Epoch [6/10], Step [60/115], Loss: 0.2316\n",
            "Epoch [6/10], Step [80/115], Loss: 0.2608\n",
            "Epoch [6/10], Step [100/115], Loss: 0.3504\n",
            "Epoch [7/10], Step [20/115], Loss: 0.3804\n",
            "Epoch [7/10], Step [40/115], Loss: 0.3217\n",
            "Epoch [7/10], Step [60/115], Loss: 0.5541\n",
            "Epoch [7/10], Step [80/115], Loss: 0.7188\n",
            "Epoch [7/10], Step [100/115], Loss: 0.2195\n",
            "Epoch [8/10], Step [20/115], Loss: 0.0604\n",
            "Epoch [8/10], Step [40/115], Loss: 0.2529\n",
            "Epoch [8/10], Step [60/115], Loss: 0.1746\n",
            "Epoch [8/10], Step [80/115], Loss: 0.3113\n",
            "Epoch [8/10], Step [100/115], Loss: 0.1234\n",
            "Epoch [9/10], Step [20/115], Loss: 0.1351\n",
            "Epoch [9/10], Step [40/115], Loss: 0.2925\n",
            "Epoch [9/10], Step [60/115], Loss: 0.2461\n",
            "Epoch [9/10], Step [80/115], Loss: 0.1856\n",
            "Epoch [9/10], Step [100/115], Loss: 0.6311\n",
            "Epoch [10/10], Step [20/115], Loss: 0.2057\n",
            "Epoch [10/10], Step [40/115], Loss: 0.2467\n",
            "Epoch [10/10], Step [60/115], Loss: 0.2371\n",
            "Epoch [10/10], Step [80/115], Loss: 0.0690\n",
            "Epoch [10/10], Step [100/115], Loss: 0.2443\n",
            "Training completed in 260.85 seconds.\n",
            "Test Accuracy: 69.69%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "    batch_size = 64\n",
        "    num_workers = 8\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_loader, test_loader = load_data(data_dir, batch_size, num_workers)\n",
        "    model = create_model(50)\n",
        "    train_model(model, train_loader, device)\n",
        "    evaluate_model(model, test_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
