{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow2oM_NYc8bo",
        "outputId": "f18f0e5c-d11a-4040-b8d3-2c9f8f18c6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f9o2lWdnc-kE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "EfzTUgyngvbi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setting up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Parameters\n",
        "batch_size = 64\n",
        "num_workers = 8\n",
        "pin_memory = True\n",
        "training_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data loading and transformation setup\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the dataset and split into training and testing\n",
        "def load_split_data(root_dir, valid_size=0.2):\n",
        "    dataset = ImageFolder(root=root_dir, transform=data_transforms)\n",
        "    classes = dataset.classes\n",
        "    class_to_idx = dataset.class_to_idx\n",
        "    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=valid_size, stratify=dataset.targets)\n",
        "\n",
        "    # Calculate class weights and prepare the sampler\n",
        "    class_counts = torch.bincount(torch.tensor(dataset.targets))\n",
        "    class_weights = 1. / (class_counts.float() + 1e-6)\n",
        "    sample_weights = class_weights[dataset.targets]\n",
        "    sampler = WeightedRandomSampler(sample_weights[train_idx], num_samples=len(train_idx), replacement=True)\n",
        "\n",
        "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "    test_subset = torch.utils.data.Subset(dataset, test_idx)\n",
        "    train_loader = DataLoader(train_subset, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    return train_loader, test_loader, classes\n",
        "\n",
        "train_loader, test_loader, classes = load_split_data('/content/drive/MyDrive/JPEGImages')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbcCM4LKkQBb",
        "outputId": "d38f4b34-292f-4838-c3d1-2a2ea1f7503a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Model definition\n",
        "def create_model(num_classes):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, num_classes),\n",
        "        nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "    return model.to(device)\n",
        "\n",
        "model = create_model(len(classes))\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
        "\n",
        "# Enable mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TEeVl7YakOQS"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(training_epochs):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 20 == 19:\n",
        "                print(f'Epoch {epoch + 1}, Step {i + 1}, Loss: {running_loss / 20}')\n",
        "                running_loss = 0.0\n",
        "        end_time = time.time()\n",
        "        print(f'Epoch {epoch + 1} completed in {end_time - start_time:.2f} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WMuu9aMbkLUh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model evaluation\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Cvu_Pi44K5",
        "outputId": "a2928f18-e112-4ddf-ea5e-708071fca6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 20, Loss: 3.30799024105072\n",
            "Epoch 1, Step 40, Loss: 1.9609145820140839\n",
            "Epoch 1, Step 60, Loss: 1.2360934972763062\n",
            "Epoch 1, Step 80, Loss: 0.9123417884111404\n",
            "Epoch 1, Step 100, Loss: 0.783375883102417\n",
            "Epoch 1, Step 120, Loss: 0.7305864036083222\n",
            "Epoch 1 completed in 27.54 seconds\n",
            "Epoch 2, Step 20, Loss: 0.6360910266637803\n",
            "Epoch 2, Step 40, Loss: 0.6424988746643067\n",
            "Epoch 2, Step 60, Loss: 0.5469781264662743\n",
            "Epoch 2, Step 80, Loss: 0.4926511198282242\n",
            "Epoch 2, Step 100, Loss: 0.5562603548169136\n",
            "Epoch 2, Step 120, Loss: 0.4854041576385498\n",
            "Epoch 2 completed in 27.37 seconds\n",
            "Epoch 3, Step 20, Loss: 0.4865072265267372\n",
            "Epoch 3, Step 40, Loss: 0.43984404355287554\n",
            "Epoch 3, Step 60, Loss: 0.41095187067985534\n",
            "Epoch 3, Step 80, Loss: 0.4568556137382984\n",
            "Epoch 3, Step 100, Loss: 0.4341370686888695\n",
            "Epoch 3, Step 120, Loss: 0.3708513617515564\n",
            "Epoch 3 completed in 27.19 seconds\n",
            "Epoch 4, Step 20, Loss: 0.38141823187470436\n",
            "Epoch 4, Step 40, Loss: 0.39135692194104194\n",
            "Epoch 4, Step 60, Loss: 0.37487342953681946\n",
            "Epoch 4, Step 80, Loss: 0.3678396582603455\n",
            "Epoch 4, Step 100, Loss: 0.3353031940758228\n",
            "Epoch 4, Step 120, Loss: 0.3147589094936848\n",
            "Epoch 4 completed in 27.07 seconds\n",
            "Epoch 5, Step 20, Loss: 0.3470218688249588\n",
            "Epoch 5, Step 40, Loss: 0.2890803121030331\n",
            "Epoch 5, Step 60, Loss: 0.34573434144258497\n",
            "Epoch 5, Step 80, Loss: 0.37683945819735526\n",
            "Epoch 5, Step 100, Loss: 0.29361952617764475\n",
            "Epoch 5, Step 120, Loss: 0.3976947791874409\n",
            "Epoch 5 completed in 27.20 seconds\n",
            "Epoch 6, Step 20, Loss: 0.2971901871263981\n",
            "Epoch 6, Step 40, Loss: 0.33124345988035203\n",
            "Epoch 6, Step 60, Loss: 0.32370408400893214\n",
            "Epoch 6, Step 80, Loss: 0.29916809126734734\n",
            "Epoch 6, Step 100, Loss: 0.27022976130247117\n",
            "Epoch 6, Step 120, Loss: 0.3106461733579636\n",
            "Epoch 6 completed in 26.78 seconds\n",
            "Epoch 7, Step 20, Loss: 0.28550580590963365\n",
            "Epoch 7, Step 40, Loss: 0.30246507450938226\n",
            "Epoch 7, Step 60, Loss: 0.2801265560090542\n",
            "Epoch 7, Step 80, Loss: 0.29598505422472954\n",
            "Epoch 7, Step 100, Loss: 0.28246908001601695\n",
            "Epoch 7, Step 120, Loss: 0.26640645787119865\n",
            "Epoch 7 completed in 27.14 seconds\n",
            "Epoch 8, Step 20, Loss: 0.27438611835241317\n",
            "Epoch 8, Step 40, Loss: 0.2850399844348431\n",
            "Epoch 8, Step 60, Loss: 0.28028117269277575\n",
            "Epoch 8, Step 80, Loss: 0.2626275047659874\n",
            "Epoch 8, Step 100, Loss: 0.25799432918429377\n",
            "Epoch 8, Step 120, Loss: 0.2757833402603865\n",
            "Epoch 8 completed in 26.90 seconds\n",
            "Epoch 9, Step 20, Loss: 0.24024856835603714\n",
            "Epoch 9, Step 40, Loss: 0.27944949865341184\n",
            "Epoch 9, Step 60, Loss: 0.2153507240116596\n",
            "Epoch 9, Step 80, Loss: 0.24371339976787568\n",
            "Epoch 9, Step 100, Loss: 0.23165735304355622\n",
            "Epoch 9, Step 120, Loss: 0.24595504999160767\n",
            "Epoch 9 completed in 26.97 seconds\n",
            "Epoch 10, Step 20, Loss: 0.21209781281650067\n",
            "Epoch 10, Step 40, Loss: 0.2526017092168331\n",
            "Epoch 10, Step 60, Loss: 0.24084538593888283\n",
            "Epoch 10, Step 80, Loss: 0.24862182065844535\n",
            "Epoch 10, Step 100, Loss: 0.2354463405907154\n",
            "Epoch 10, Step 120, Loss: 0.2270616866648197\n",
            "Epoch 10 completed in 27.11 seconds\n",
            "Accuracy of the model on the test images: 90.52938319572608%\n"
          ]
        }
      ],
      "source": [
        "train_model()\n",
        "evaluate_model()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
