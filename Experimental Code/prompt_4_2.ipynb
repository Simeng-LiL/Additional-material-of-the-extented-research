{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpxHnFrHBxUd",
        "outputId": "263f5095-f669-45f5-c8f1-79d488adf85b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RS8jnLMBBuYx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch import nn, optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Path to the dataset\n",
        "data_dir = '/content/drive/MyDrive/JPEGImages'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y1szMA1XB7XC"
      },
      "outputs": [],
      "source": [
        "# 1. Data Loading and Preprocessing\n",
        "def load_split_data(data_dir, is_train=True):\n",
        "    \"\"\" Load and preprocess data, returning a DataLoader. \"\"\"\n",
        "    transform = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    dataset = ImageFolder(root=data_dir, transform=transform['train' if is_train else 'test'])\n",
        "    if is_train:\n",
        "        class_counts = [0] * 50\n",
        "        for _, target in dataset.samples:\n",
        "            class_counts[target] += 1\n",
        "        class_weights = [1 / (count + 1e-6) for count in class_counts]\n",
        "        sample_weights = [class_weights[target] for _, target in dataset.samples]\n",
        "        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "        loader = DataLoader(dataset, batch_size=64, sampler=sampler, num_workers=8, pin_memory=True)\n",
        "    else:\n",
        "        loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    return loader\n",
        "\n",
        "train_loader = load_split_data(data_dir, is_train=True)\n",
        "test_loader = load_split_data(data_dir, is_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKxfnsYwBvBr",
        "outputId": "df76c60c-3470-4dbf-fbb8-f3e6ffa9d099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 2. Model Definition\n",
        "def get_model(num_classes=50):\n",
        "    model = resnet50(pretrained=True)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model = model.cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A7IqF9n2CZ7B"
      },
      "outputs": [],
      "source": [
        "# 3. Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_model():\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    for epoch in range(10):\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f\"Epoch {epoch}, Step {i}, Loss: {loss.item()}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    print(f\"Total training time: {total_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JrKueCkLCbj8"
      },
      "outputs": [],
      "source": [
        "# 4. Evaluation\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy on the test set: {100 * correct / total}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEk4YFe9Ccvb",
        "outputId": "307e3e74-f730-49ed-d482-c991db368c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Step 0, Loss: 2.6421828269958496\n",
            "Epoch 0, Step 20, Loss: 2.7917087078094482\n",
            "Epoch 0, Step 40, Loss: 2.0624160766601562\n",
            "Epoch 0, Step 60, Loss: 2.3145625591278076\n",
            "Epoch 0, Step 80, Loss: 1.890323519706726\n",
            "Epoch 0, Step 100, Loss: 1.4729232788085938\n",
            "Epoch 0, Step 120, Loss: 1.4799585342407227\n",
            "Epoch 0, Step 140, Loss: 1.6700005531311035\n",
            "Epoch 0, Step 160, Loss: 1.5505094528198242\n",
            "Epoch 1, Step 0, Loss: 1.6505286693572998\n",
            "Epoch 1, Step 20, Loss: 1.671342134475708\n",
            "Epoch 1, Step 40, Loss: 1.6563447713851929\n",
            "Epoch 1, Step 60, Loss: 1.389883041381836\n",
            "Epoch 1, Step 80, Loss: 1.5580463409423828\n",
            "Epoch 1, Step 100, Loss: 1.309066891670227\n",
            "Epoch 1, Step 120, Loss: 1.1400022506713867\n",
            "Epoch 1, Step 140, Loss: 1.4351556301116943\n",
            "Epoch 1, Step 160, Loss: 1.5998358726501465\n",
            "Epoch 2, Step 0, Loss: 0.9827694892883301\n",
            "Epoch 2, Step 20, Loss: 1.0731240510940552\n",
            "Epoch 2, Step 40, Loss: 1.4540128707885742\n",
            "Epoch 2, Step 60, Loss: 0.9684163331985474\n",
            "Epoch 2, Step 80, Loss: 1.4796311855316162\n",
            "Epoch 2, Step 100, Loss: 1.183596134185791\n",
            "Epoch 2, Step 120, Loss: 1.034104585647583\n",
            "Epoch 2, Step 140, Loss: 1.0322966575622559\n",
            "Epoch 2, Step 160, Loss: 1.2177444696426392\n",
            "Epoch 3, Step 0, Loss: 0.9449566602706909\n",
            "Epoch 3, Step 20, Loss: 1.1501832008361816\n",
            "Epoch 3, Step 40, Loss: 1.210517168045044\n",
            "Epoch 3, Step 60, Loss: 0.9738344550132751\n",
            "Epoch 3, Step 80, Loss: 1.0153093338012695\n",
            "Epoch 3, Step 100, Loss: 1.0889451503753662\n",
            "Epoch 3, Step 120, Loss: 1.1028623580932617\n",
            "Epoch 3, Step 140, Loss: 0.760016679763794\n",
            "Epoch 3, Step 160, Loss: 0.9187202453613281\n",
            "Epoch 4, Step 0, Loss: 0.8284907341003418\n",
            "Epoch 4, Step 20, Loss: 1.218356966972351\n",
            "Epoch 4, Step 40, Loss: 0.8212772011756897\n",
            "Epoch 4, Step 60, Loss: 0.5725691914558411\n",
            "Epoch 4, Step 80, Loss: 0.5919200778007507\n",
            "Epoch 4, Step 100, Loss: 0.7382677793502808\n",
            "Epoch 4, Step 120, Loss: 0.697272002696991\n",
            "Epoch 4, Step 140, Loss: 0.5504539012908936\n",
            "Epoch 4, Step 160, Loss: 0.577703058719635\n",
            "Epoch 5, Step 0, Loss: 0.835673987865448\n",
            "Epoch 5, Step 20, Loss: 0.6530852913856506\n",
            "Epoch 5, Step 40, Loss: 0.7083112001419067\n",
            "Epoch 5, Step 60, Loss: 0.7508277297019958\n",
            "Epoch 5, Step 80, Loss: 0.4200900197029114\n",
            "Epoch 5, Step 100, Loss: 0.7180410623550415\n",
            "Epoch 5, Step 120, Loss: 0.4987140893936157\n",
            "Epoch 5, Step 140, Loss: 0.6004018783569336\n",
            "Epoch 5, Step 160, Loss: 0.5743298530578613\n",
            "Epoch 6, Step 0, Loss: 0.9996120929718018\n",
            "Epoch 6, Step 20, Loss: 0.5101710557937622\n",
            "Epoch 6, Step 40, Loss: 0.5431683659553528\n",
            "Epoch 6, Step 60, Loss: 0.5810756683349609\n",
            "Epoch 6, Step 80, Loss: 0.5016442537307739\n",
            "Epoch 6, Step 100, Loss: 0.6320885419845581\n",
            "Epoch 6, Step 120, Loss: 0.6216312050819397\n",
            "Epoch 6, Step 140, Loss: 0.8185506463050842\n",
            "Epoch 6, Step 160, Loss: 0.6607375741004944\n",
            "Epoch 7, Step 0, Loss: 0.3907962441444397\n",
            "Epoch 7, Step 20, Loss: 0.40902695059776306\n",
            "Epoch 7, Step 40, Loss: 0.6192784309387207\n",
            "Epoch 7, Step 60, Loss: 0.3928740918636322\n",
            "Epoch 7, Step 80, Loss: 0.5661661028862\n",
            "Epoch 7, Step 100, Loss: 0.5113632678985596\n",
            "Epoch 7, Step 120, Loss: 0.46640560030937195\n",
            "Epoch 7, Step 140, Loss: 0.5877965688705444\n",
            "Epoch 7, Step 160, Loss: 0.4159516394138336\n",
            "Epoch 8, Step 0, Loss: 0.35406580567359924\n",
            "Epoch 8, Step 20, Loss: 0.47949230670928955\n",
            "Epoch 8, Step 40, Loss: 0.36919423937797546\n",
            "Epoch 8, Step 60, Loss: 0.5188252329826355\n",
            "Epoch 8, Step 80, Loss: 0.2697964012622833\n",
            "Epoch 8, Step 100, Loss: 0.3830506503582001\n",
            "Epoch 8, Step 120, Loss: 0.598810076713562\n",
            "Epoch 8, Step 140, Loss: 0.540120542049408\n",
            "Epoch 8, Step 160, Loss: 0.694560706615448\n",
            "Epoch 9, Step 0, Loss: 0.5253403782844543\n",
            "Epoch 9, Step 20, Loss: 0.3190552294254303\n",
            "Epoch 9, Step 40, Loss: 0.40218594670295715\n",
            "Epoch 9, Step 60, Loss: 0.42526692152023315\n",
            "Epoch 9, Step 80, Loss: 0.6101744174957275\n",
            "Epoch 9, Step 100, Loss: 0.33130547404289246\n",
            "Epoch 9, Step 120, Loss: 0.3418272137641907\n",
            "Epoch 9, Step 140, Loss: 0.5884107947349548\n",
            "Epoch 9, Step 160, Loss: 0.5116098523139954\n",
            "Total training time: 983.56 seconds\n",
            "Accuracy on the test set: 89.74832377805849%\n"
          ]
        }
      ],
      "source": [
        "train_model()\n",
        "evaluate_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
