{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqAXNHw4m2X",
        "outputId": "a4d3b6c8-6fa2-48f9-8392-8cb40ae4b48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "tv2GNRNk4NjR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler, random_split, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Amt-MA7MowQM"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "DATA_DIR = '/content/drive/MyDrive/JPEGImages'\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 8\n",
        "PIN_MEMORY = True\n",
        "TRAINING_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images to 224x224\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the images\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder(root=DATA_DIR, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "JGWpClB1oyA7"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights for balancing training data\n",
        "class_counts = torch.tensor([label for label in dataset.targets]).bincount().float()\n",
        "class_weights = 1.0 / (class_counts + 1e-6)  # Add a small constant to avoid division by zero\n",
        "sample_weights = class_weights[torch.tensor(dataset.targets)]\n",
        "\n",
        "# Create a sampler for weighted sampling\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_indices, test_indices = random_split(range(len(dataset)), [train_size, test_size])\n",
        "\n",
        "# Create subset samplers for train and test to avoid index error\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler,\n",
        "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "U1XAjgEvo0mO"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "model = models.resnet50(pretrained=True)  # Use a pretrained ResNet-50 model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # Freeze all layers\n",
        "\n",
        "# Add custom classifier\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 50),  # Assuming 50 animal classes\n",
        "    nn.BatchNorm1d(50),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "# Model training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n",
        "scaler = torch.cuda.amp.GradScaler()  # For mixed precision training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUsfKwfVlypt",
        "outputId": "21821d74-33b2-4c0f-92cf-edc59805449e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [20/129], Loss: 1.9514\n",
            "Epoch [1/10], Step [40/129], Loss: 1.5154\n",
            "Epoch [1/10], Step [60/129], Loss: 1.5276\n",
            "Epoch [1/10], Step [80/129], Loss: 1.3371\n",
            "Epoch [1/10], Step [100/129], Loss: 1.4626\n",
            "Epoch [1/10], Step [120/129], Loss: 1.0899\n",
            "Training time for epoch 1: 28.32 seconds\n",
            "Epoch [2/10], Step [20/129], Loss: 1.1351\n",
            "Epoch [2/10], Step [40/129], Loss: 0.9294\n",
            "Epoch [2/10], Step [60/129], Loss: 1.0616\n",
            "Epoch [2/10], Step [80/129], Loss: 0.9491\n",
            "Epoch [2/10], Step [100/129], Loss: 1.1489\n",
            "Epoch [2/10], Step [120/129], Loss: 0.7633\n",
            "Training time for epoch 2: 27.78 seconds\n",
            "Epoch [3/10], Step [20/129], Loss: 0.9612\n",
            "Epoch [3/10], Step [40/129], Loss: 1.0638\n",
            "Epoch [3/10], Step [60/129], Loss: 0.8275\n",
            "Epoch [3/10], Step [80/129], Loss: 1.0207\n",
            "Epoch [3/10], Step [100/129], Loss: 0.9564\n",
            "Epoch [3/10], Step [120/129], Loss: 1.0157\n",
            "Training time for epoch 3: 28.22 seconds\n",
            "Epoch [4/10], Step [20/129], Loss: 0.7981\n",
            "Epoch [4/10], Step [40/129], Loss: 1.0425\n",
            "Epoch [4/10], Step [60/129], Loss: 0.9293\n",
            "Epoch [4/10], Step [80/129], Loss: 0.6244\n",
            "Epoch [4/10], Step [100/129], Loss: 0.7928\n",
            "Epoch [4/10], Step [120/129], Loss: 0.9897\n",
            "Training time for epoch 4: 27.76 seconds\n",
            "Epoch [5/10], Step [20/129], Loss: 0.8665\n",
            "Epoch [5/10], Step [40/129], Loss: 0.6763\n",
            "Epoch [5/10], Step [60/129], Loss: 0.6638\n",
            "Epoch [5/10], Step [80/129], Loss: 0.7391\n",
            "Epoch [5/10], Step [100/129], Loss: 0.8997\n",
            "Epoch [5/10], Step [120/129], Loss: 0.6948\n",
            "Training time for epoch 5: 28.17 seconds\n",
            "Epoch [6/10], Step [20/129], Loss: 0.9703\n",
            "Epoch [6/10], Step [40/129], Loss: 0.6917\n",
            "Epoch [6/10], Step [60/129], Loss: 0.9507\n",
            "Epoch [6/10], Step [80/129], Loss: 0.8654\n",
            "Epoch [6/10], Step [100/129], Loss: 0.9154\n",
            "Epoch [6/10], Step [120/129], Loss: 0.6525\n",
            "Training time for epoch 6: 27.94 seconds\n",
            "Epoch [7/10], Step [20/129], Loss: 0.5323\n",
            "Epoch [7/10], Step [40/129], Loss: 0.6210\n",
            "Epoch [7/10], Step [60/129], Loss: 0.6781\n",
            "Epoch [7/10], Step [80/129], Loss: 0.6544\n",
            "Epoch [7/10], Step [100/129], Loss: 0.5119\n",
            "Epoch [7/10], Step [120/129], Loss: 0.7529\n",
            "Training time for epoch 7: 27.51 seconds\n",
            "Epoch [8/10], Step [20/129], Loss: 0.6485\n",
            "Epoch [8/10], Step [40/129], Loss: 0.6379\n",
            "Epoch [8/10], Step [60/129], Loss: 0.6277\n",
            "Epoch [8/10], Step [80/129], Loss: 0.6009\n",
            "Epoch [8/10], Step [100/129], Loss: 0.7653\n",
            "Epoch [8/10], Step [120/129], Loss: 0.5609\n",
            "Training time for epoch 8: 27.78 seconds\n",
            "Epoch [9/10], Step [20/129], Loss: 0.6056\n",
            "Epoch [9/10], Step [40/129], Loss: 0.6995\n",
            "Epoch [9/10], Step [60/129], Loss: 0.6875\n",
            "Epoch [9/10], Step [80/129], Loss: 0.6997\n",
            "Epoch [9/10], Step [100/129], Loss: 0.6683\n",
            "Epoch [9/10], Step [120/129], Loss: 0.6635\n",
            "Training time for epoch 9: 27.39 seconds\n",
            "Epoch [10/10], Step [20/129], Loss: 0.5553\n",
            "Epoch [10/10], Step [40/129], Loss: 0.7097\n",
            "Epoch [10/10], Step [60/129], Loss: 0.5159\n",
            "Epoch [10/10], Step [80/129], Loss: 0.5708\n",
            "Epoch [10/10], Step [100/129], Loss: 0.6887\n",
            "Epoch [10/10], Step [120/129], Loss: 0.4465\n",
            "Training time for epoch 10: 27.62 seconds\n"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "for epoch in range(TRAINING_EPOCHS):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start timing the training\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{TRAINING_EPOCHS}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    end_time = time.time()  # End timing the training\n",
        "    print(f\"Training time for epoch {epoch + 1}: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icakLSqPZ26c",
        "outputId": "3af35408-3dd0-43ae-a5c9-0c334ed58090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 90.58%\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
