{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoF6EAb1fDMo",
        "outputId": "856afa73-9a78-43a9-a9fd-978823de9d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YhjzF-68fJ0d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I8FnYvSefWGV"
      },
      "outputs": [],
      "source": [
        "def load_data(image_dir):\n",
        "    # Load all image files and split into train and test datasets\n",
        "    classes = [d.name for d in os.scandir(image_dir) if d.is_dir()]\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(image_dir, class_name)\n",
        "        files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) if f.endswith('.jpg')]\n",
        "        file_paths.extend(files)\n",
        "        labels.extend([i] * len(files))\n",
        "\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "    return train_paths, test_paths, train_labels, test_labels, classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gBiCPd7CfYgF"
      },
      "outputs": [],
      "source": [
        "def create_data_loaders(train_paths, test_paths, train_labels, test_labels):\n",
        "    # Data transformations\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Custom dataset class\n",
        "    class CustomDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, paths, labels, transform):\n",
        "            self.paths = paths\n",
        "            self.labels = labels\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.paths)\n",
        "\n",
        "        def __getitem__(self, index):\n",
        "            image = Image.open(self.paths[index]).convert('RGB')\n",
        "            label = self.labels[index]\n",
        "            return self.transform(image), label\n",
        "\n",
        "    # Class weighting for imbalanced classes\n",
        "    count = Counter(train_labels)\n",
        "    class_weights = torch.tensor([1 / (count[i] + 1e-6) for i in range(len(count))], dtype=torch.float32)\n",
        "    samples_weight = class_weights[train_labels]\n",
        "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "    train_dataset = CustomDataset(train_paths, train_labels, train_transform)\n",
        "    test_dataset = CustomDataset(test_paths, test_labels, test_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler, num_workers=8, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bi5_TvRofcTZ"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "def define_model(num_classes):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6wqvamyJfeZN"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "def train_model(model, train_loader, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(10):  # train for 10 epochs\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Step {i+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_duration = end_time - start_time\n",
        "        print(f'Epoch {epoch + 1} completed in {epoch_duration:.2f} seconds')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SYlW98qffhPX"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcQj8f8DfjSH",
        "outputId": "034c6aab-2a91-47c6-d9c7-05f4c1ca7bd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 20, Loss: 3.0218\n",
            "Epoch 1, Step 40, Loss: 2.6686\n",
            "Epoch 1, Step 60, Loss: 2.3348\n",
            "Epoch 1, Step 80, Loss: 1.9937\n",
            "Epoch 1, Step 100, Loss: 1.7222\n",
            "Epoch 1, Step 120, Loss: 1.8468\n",
            "Epoch 1 completed in 42.05 seconds\n",
            "Epoch 2, Step 20, Loss: 1.8759\n",
            "Epoch 2, Step 40, Loss: 1.4452\n",
            "Epoch 2, Step 60, Loss: 1.5666\n",
            "Epoch 2, Step 80, Loss: 1.4433\n",
            "Epoch 2, Step 100, Loss: 1.4067\n",
            "Epoch 2, Step 120, Loss: 1.4588\n",
            "Epoch 2 completed in 41.54 seconds\n",
            "Epoch 3, Step 20, Loss: 1.3716\n",
            "Epoch 3, Step 40, Loss: 1.4406\n",
            "Epoch 3, Step 60, Loss: 0.9859\n",
            "Epoch 3, Step 80, Loss: 1.2322\n",
            "Epoch 3, Step 100, Loss: 1.3057\n",
            "Epoch 3, Step 120, Loss: 1.0770\n",
            "Epoch 3 completed in 41.56 seconds\n",
            "Epoch 4, Step 20, Loss: 0.9321\n",
            "Epoch 4, Step 40, Loss: 1.0149\n",
            "Epoch 4, Step 60, Loss: 0.9969\n",
            "Epoch 4, Step 80, Loss: 1.1406\n",
            "Epoch 4, Step 100, Loss: 1.1979\n",
            "Epoch 4, Step 120, Loss: 0.8895\n",
            "Epoch 4 completed in 41.61 seconds\n",
            "Epoch 5, Step 20, Loss: 1.0547\n",
            "Epoch 5, Step 40, Loss: 1.1319\n",
            "Epoch 5, Step 60, Loss: 0.9568\n",
            "Epoch 5, Step 80, Loss: 0.9950\n",
            "Epoch 5, Step 100, Loss: 0.6195\n",
            "Epoch 5, Step 120, Loss: 1.1827\n",
            "Epoch 5 completed in 41.60 seconds\n",
            "Epoch 6, Step 20, Loss: 0.9231\n",
            "Epoch 6, Step 40, Loss: 0.7352\n",
            "Epoch 6, Step 60, Loss: 0.7198\n",
            "Epoch 6, Step 80, Loss: 0.8880\n",
            "Epoch 6, Step 100, Loss: 0.9655\n",
            "Epoch 6, Step 120, Loss: 0.6954\n",
            "Epoch 6 completed in 41.49 seconds\n",
            "Epoch 7, Step 20, Loss: 1.0187\n",
            "Epoch 7, Step 40, Loss: 0.9269\n",
            "Epoch 7, Step 60, Loss: 1.0839\n",
            "Epoch 7, Step 80, Loss: 0.8203\n",
            "Epoch 7, Step 100, Loss: 0.7762\n",
            "Epoch 7, Step 120, Loss: 0.6201\n",
            "Epoch 7 completed in 41.66 seconds\n",
            "Epoch 8, Step 20, Loss: 0.7282\n",
            "Epoch 8, Step 40, Loss: 0.5864\n",
            "Epoch 8, Step 60, Loss: 0.5919\n",
            "Epoch 8, Step 80, Loss: 0.6755\n",
            "Epoch 8, Step 100, Loss: 0.7826\n",
            "Epoch 8, Step 120, Loss: 0.8691\n",
            "Epoch 8 completed in 41.57 seconds\n",
            "Epoch 9, Step 20, Loss: 0.4794\n",
            "Epoch 9, Step 40, Loss: 0.4890\n",
            "Epoch 9, Step 60, Loss: 0.3856\n",
            "Epoch 9, Step 80, Loss: 0.5279\n",
            "Epoch 9, Step 100, Loss: 0.7774\n",
            "Epoch 9, Step 120, Loss: 0.4004\n",
            "Epoch 9 completed in 41.51 seconds\n",
            "Epoch 10, Step 20, Loss: 0.4966\n",
            "Epoch 10, Step 40, Loss: 0.5963\n",
            "Epoch 10, Step 60, Loss: 0.6230\n",
            "Epoch 10, Step 80, Loss: 0.2351\n",
            "Epoch 10, Step 100, Loss: 0.6452\n",
            "Epoch 10, Step 120, Loss: 0.4175\n",
            "Epoch 10 completed in 41.62 seconds\n",
            "Accuracy: 69.64545896066052%\n"
          ]
        }
      ],
      "source": [
        "# Main function\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    image_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "    train_paths, test_paths, train_labels, test_labels, classes = load_data(image_dir)\n",
        "    train_loader, test_loader = create_data_loaders(train_paths, test_paths, train_labels, test_labels)\n",
        "    model = define_model(len(classes))\n",
        "    train_model(model, train_loader, device)\n",
        "    evaluate_model(model, test_loader, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
