{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqAXNHw4m2X",
        "outputId": "a4d3b6c8-6fa2-48f9-8392-8cb40ae4b48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "tv2GNRNk4NjR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision.models import resnet50\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "icakLSqPZ26c"
      },
      "outputs": [],
      "source": [
        "# Path to the JPEGImages folder\n",
        "data_dir = Path('/content/drive/MyDrive/JPEGImages')\n",
        "\n",
        "# Data loading and preprocessing\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.train = train\n",
        "        self.classes = [d.name for d in self.root_dir.iterdir() if d.is_dir()]\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        self.samples = [(file, self.class_to_idx[file.parent.name])\n",
        "                        for cls in self.root_dir.iterdir() if cls.is_dir()\n",
        "                        for file in cls.iterdir() if file.is_file() and self.is_image_file(file.name)]\n",
        "\n",
        "        # Define transforms based on whether it's training data\n",
        "        if self.train:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def is_image_file(self, filename):\n",
        "        \"\"\"Check if a file is an image.\"\"\"\n",
        "        image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "        return any(filename.lower().endswith(ext) for ext in image_extensions)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, target = self.samples[idx]\n",
        "        try:\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error opening image: {path}, Error: {e}\")\n",
        "            # Optionally, handle corrupted files or read next file\n",
        "            return None  # Depending on your preference\n",
        "        return image, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6VXnWteMdqnl"
      },
      "outputs": [],
      "source": [
        "# Creating instances for training and testing datasets\n",
        "train_dataset = AnimalDataset(data_dir, train=True)\n",
        "test_dataset = AnimalDataset(data_dir, train=False)\n",
        "\n",
        "# Class weights and sampler setup\n",
        "class_counts = torch.zeros(len(train_dataset.classes))\n",
        "for _, index in train_dataset.samples:\n",
        "    class_counts[index] += 1\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = class_weights[[sample[1] for sample in train_dataset.samples]]\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "# DataLoader setup\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler, num_workers=8, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QYZgZ8DrdQMQ"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "model = resnet50(pretrained=True)\n",
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(model.fc.in_features, 512),\n",
        "    torch.nn.BatchNorm1d(512),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(512, 50)\n",
        ")\n",
        "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6JyZFdCZ5ws",
        "outputId": "ca86ce68-c5f7-430c-d351-1f3e70817ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 0, Loss: 3.999176025390625\n",
            "Epoch 1, Step 20, Loss: 2.70925235748291\n",
            "Epoch 1, Step 40, Loss: 2.405168294906616\n",
            "Epoch 1, Step 60, Loss: 2.172438859939575\n",
            "Epoch 1, Step 80, Loss: 2.2899551391601562\n",
            "Epoch 1, Step 100, Loss: 1.7975573539733887\n",
            "Epoch 1, Step 120, Loss: 1.865185260772705\n",
            "Epoch 1, Step 140, Loss: 1.5738177299499512\n",
            "Epoch 1, Step 160, Loss: 1.783432960510254\n",
            "Epoch 1 completed in 37.92 seconds\n",
            "Epoch 2, Step 0, Loss: 1.4050970077514648\n",
            "Epoch 2, Step 20, Loss: 1.669276475906372\n",
            "Epoch 2, Step 40, Loss: 1.6496264934539795\n",
            "Epoch 2, Step 60, Loss: 1.626551866531372\n",
            "Epoch 2, Step 80, Loss: 1.5257282257080078\n",
            "Epoch 2, Step 100, Loss: 1.2218142747879028\n",
            "Epoch 2, Step 120, Loss: 1.2127766609191895\n",
            "Epoch 2, Step 140, Loss: 1.125311017036438\n",
            "Epoch 2, Step 160, Loss: 1.0908727645874023\n",
            "Epoch 2 completed in 37.39 seconds\n",
            "Epoch 3, Step 0, Loss: 1.372619390487671\n",
            "Epoch 3, Step 20, Loss: 0.9384704232215881\n",
            "Epoch 3, Step 40, Loss: 1.3091274499893188\n",
            "Epoch 3, Step 60, Loss: 1.5328093767166138\n",
            "Epoch 3, Step 80, Loss: 1.1253267526626587\n",
            "Epoch 3, Step 100, Loss: 1.0589548349380493\n",
            "Epoch 3, Step 120, Loss: 1.0415250062942505\n",
            "Epoch 3, Step 140, Loss: 0.9009919166564941\n",
            "Epoch 3, Step 160, Loss: 1.132830023765564\n",
            "Epoch 3 completed in 37.77 seconds\n",
            "Epoch 4, Step 0, Loss: 1.0026674270629883\n",
            "Epoch 4, Step 20, Loss: 0.7440134286880493\n",
            "Epoch 4, Step 40, Loss: 0.922090470790863\n",
            "Epoch 4, Step 60, Loss: 1.0956447124481201\n",
            "Epoch 4, Step 80, Loss: 0.9408050775527954\n",
            "Epoch 4, Step 100, Loss: 0.8447920083999634\n",
            "Epoch 4, Step 120, Loss: 0.9922911524772644\n",
            "Epoch 4, Step 140, Loss: 1.0229394435882568\n",
            "Epoch 4, Step 160, Loss: 1.2401200532913208\n",
            "Epoch 4 completed in 37.50 seconds\n",
            "Epoch 5, Step 0, Loss: 0.7635954022407532\n",
            "Epoch 5, Step 20, Loss: 0.903998851776123\n",
            "Epoch 5, Step 40, Loss: 0.9706403017044067\n",
            "Epoch 5, Step 60, Loss: 0.7949751019477844\n",
            "Epoch 5, Step 80, Loss: 0.8384957909584045\n",
            "Epoch 5, Step 100, Loss: 1.2532129287719727\n",
            "Epoch 5, Step 120, Loss: 0.6841579675674438\n",
            "Epoch 5, Step 140, Loss: 0.5180768966674805\n",
            "Epoch 5, Step 160, Loss: 1.2783665657043457\n",
            "Epoch 5 completed in 37.82 seconds\n",
            "Epoch 6, Step 0, Loss: 0.5649733543395996\n",
            "Epoch 6, Step 20, Loss: 0.7912544012069702\n",
            "Epoch 6, Step 40, Loss: 0.7573240995407104\n",
            "Epoch 6, Step 60, Loss: 0.609826922416687\n",
            "Epoch 6, Step 80, Loss: 0.6122825145721436\n",
            "Epoch 6, Step 100, Loss: 0.6584641933441162\n",
            "Epoch 6, Step 120, Loss: 0.6200535297393799\n",
            "Epoch 6, Step 140, Loss: 0.6737457513809204\n",
            "Epoch 6, Step 160, Loss: 0.7910667657852173\n",
            "Epoch 6 completed in 37.88 seconds\n",
            "Epoch 7, Step 0, Loss: 0.6679958701133728\n",
            "Epoch 7, Step 20, Loss: 0.4218341112136841\n",
            "Epoch 7, Step 40, Loss: 0.813764750957489\n",
            "Epoch 7, Step 60, Loss: 0.6933355331420898\n",
            "Epoch 7, Step 80, Loss: 0.8643589019775391\n",
            "Epoch 7, Step 100, Loss: 0.5338802337646484\n",
            "Epoch 7, Step 120, Loss: 0.6134849786758423\n",
            "Epoch 7, Step 140, Loss: 0.9264144897460938\n",
            "Epoch 7, Step 160, Loss: 0.4415455162525177\n",
            "Epoch 7 completed in 37.62 seconds\n",
            "Epoch 8, Step 0, Loss: 0.45285913348197937\n",
            "Epoch 8, Step 20, Loss: 0.9412097930908203\n",
            "Epoch 8, Step 40, Loss: 0.6013374328613281\n",
            "Epoch 8, Step 60, Loss: 0.6252244114875793\n",
            "Epoch 8, Step 80, Loss: 0.3193204402923584\n",
            "Epoch 8, Step 100, Loss: 0.5401076078414917\n",
            "Epoch 8, Step 120, Loss: 0.37626194953918457\n",
            "Epoch 8, Step 140, Loss: 0.4986632168292999\n",
            "Epoch 8, Step 160, Loss: 0.39347517490386963\n",
            "Epoch 8 completed in 37.43 seconds\n",
            "Epoch 9, Step 0, Loss: 0.5281655788421631\n",
            "Epoch 9, Step 20, Loss: 0.9785546064376831\n",
            "Epoch 9, Step 40, Loss: 0.5570321083068848\n",
            "Epoch 9, Step 60, Loss: 0.4025498032569885\n",
            "Epoch 9, Step 80, Loss: 0.8012931942939758\n",
            "Epoch 9, Step 100, Loss: 0.4841974079608917\n",
            "Epoch 9, Step 120, Loss: 0.4746887981891632\n",
            "Epoch 9, Step 140, Loss: 0.5693480968475342\n",
            "Epoch 9, Step 160, Loss: 0.9745542407035828\n",
            "Epoch 9 completed in 37.41 seconds\n",
            "Epoch 10, Step 0, Loss: 0.5674049258232117\n",
            "Epoch 10, Step 20, Loss: 0.2715359032154083\n",
            "Epoch 10, Step 40, Loss: 0.22716200351715088\n",
            "Epoch 10, Step 60, Loss: 0.2868681848049164\n",
            "Epoch 10, Step 80, Loss: 0.3196791708469391\n",
            "Epoch 10, Step 100, Loss: 0.3969922363758087\n",
            "Epoch 10, Step 120, Loss: 0.508808970451355\n",
            "Epoch 10, Step 140, Loss: 0.40934130549430847\n",
            "Epoch 10, Step 160, Loss: 0.421559602022171\n",
            "Epoch 10 completed in 37.53 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start time measurement\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if i % 20 == 0:\n",
        "            print(f'Epoch {epoch+1}, Step {i}, Loss: {loss.item()}')\n",
        "    elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
        "    print(f'Epoch {epoch+1} completed in {elapsed_time:.2f} seconds')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtdVJ0bPZ8WI",
        "outputId": "a0e076b2-045a-4a0d-eb37-c53173c70ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 87.62996793314547%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
