{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2qjuW3gR8Kh",
        "outputId": "8e468a98-6a2a-46f0-aa09-dcb01ede283e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XsgtijCCR9HW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split, WeightedRandomSampler\n",
        "from torchvision.models import resnet50\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SzWyvi86SD_C"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_classes = 50\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data Loading and Preprocessing\n",
        "data_dir = '/content/drive/MyDrive/JPEGImages'\n",
        "\n",
        "# Transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8uVONOzzSGkq"
      },
      "outputs": [],
      "source": [
        "# Load the full dataset to split indices\n",
        "full_dataset = datasets.ImageFolder(root=data_dir)\n",
        "\n",
        "# Splitting dataset indices\n",
        "num_samples = len(full_dataset)\n",
        "indices = torch.randperm(num_samples).tolist()\n",
        "train_indices = indices[:int(0.8 * num_samples)]\n",
        "test_indices = indices[int(0.8 * num_samples):]\n",
        "\n",
        "# Load datasets with specific transforms applied\n",
        "train_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=data_dir, transform=test_transforms)\n",
        "\n",
        "# Create Subset to access the split data\n",
        "train_dataset = Subset(train_dataset, train_indices)\n",
        "test_dataset = Subset(test_dataset, test_indices)\n",
        "\n",
        "# Data Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQMtizvQSQ1J",
        "outputId": "0f2bf0b0-0ff2-43cc-c1bd-2dff39ab00e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 148MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Model Definition\n",
        "model = resnet50(pretrained=True)\n",
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(model.fc.in_features, 256),\n",
        "    torch.nn.BatchNorm1d(256),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256, num_classes)\n",
        ")\n",
        "\n",
        "# Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AlyBXBWSTKs",
        "outputId": "e57ddf83-cacf-42f6-8b21-6a4c14b69bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [20/129], Loss: 3.0276\n",
            "Epoch [1/10], Step [40/129], Loss: 2.5583\n",
            "Epoch [1/10], Step [60/129], Loss: 2.4303\n",
            "Epoch [1/10], Step [80/129], Loss: 2.3021\n",
            "Epoch [1/10], Step [100/129], Loss: 2.1257\n",
            "Epoch [1/10], Step [120/129], Loss: 2.0064\n",
            "Epoch 1 completed in 1292.24 seconds\n",
            "Epoch [2/10], Step [20/129], Loss: 1.7733\n",
            "Epoch [2/10], Step [40/129], Loss: 1.7467\n",
            "Epoch [2/10], Step [60/129], Loss: 1.8255\n",
            "Epoch [2/10], Step [80/129], Loss: 1.7391\n",
            "Epoch [2/10], Step [100/129], Loss: 1.7328\n",
            "Epoch [2/10], Step [120/129], Loss: 1.5877\n",
            "Epoch 2 completed in 40.24 seconds\n",
            "Epoch [3/10], Step [20/129], Loss: 1.5248\n",
            "Epoch [3/10], Step [40/129], Loss: 1.4967\n",
            "Epoch [3/10], Step [60/129], Loss: 1.5401\n",
            "Epoch [3/10], Step [80/129], Loss: 1.3961\n",
            "Epoch [3/10], Step [100/129], Loss: 1.3113\n",
            "Epoch [3/10], Step [120/129], Loss: 1.3142\n",
            "Epoch 3 completed in 40.70 seconds\n",
            "Epoch [4/10], Step [20/129], Loss: 1.2555\n",
            "Epoch [4/10], Step [40/129], Loss: 1.2136\n",
            "Epoch [4/10], Step [60/129], Loss: 1.1788\n",
            "Epoch [4/10], Step [80/129], Loss: 1.2793\n",
            "Epoch [4/10], Step [100/129], Loss: 1.2111\n",
            "Epoch [4/10], Step [120/129], Loss: 1.1996\n",
            "Epoch 4 completed in 40.12 seconds\n",
            "Epoch [5/10], Step [20/129], Loss: 1.0350\n",
            "Epoch [5/10], Step [40/129], Loss: 0.9871\n",
            "Epoch [5/10], Step [60/129], Loss: 1.0243\n",
            "Epoch [5/10], Step [80/129], Loss: 1.1359\n",
            "Epoch [5/10], Step [100/129], Loss: 1.1481\n",
            "Epoch [5/10], Step [120/129], Loss: 1.0880\n",
            "Epoch 5 completed in 39.91 seconds\n",
            "Epoch [6/10], Step [20/129], Loss: 0.9558\n",
            "Epoch [6/10], Step [40/129], Loss: 0.9854\n",
            "Epoch [6/10], Step [60/129], Loss: 0.8854\n",
            "Epoch [6/10], Step [80/129], Loss: 0.9476\n",
            "Epoch [6/10], Step [100/129], Loss: 0.9478\n",
            "Epoch [6/10], Step [120/129], Loss: 0.9311\n",
            "Epoch 6 completed in 40.50 seconds\n",
            "Epoch [7/10], Step [20/129], Loss: 0.8539\n",
            "Epoch [7/10], Step [40/129], Loss: 0.8134\n",
            "Epoch [7/10], Step [60/129], Loss: 0.8493\n",
            "Epoch [7/10], Step [80/129], Loss: 0.8448\n",
            "Epoch [7/10], Step [100/129], Loss: 0.8063\n",
            "Epoch [7/10], Step [120/129], Loss: 0.8697\n",
            "Epoch 7 completed in 40.50 seconds\n",
            "Epoch [8/10], Step [20/129], Loss: 0.8068\n",
            "Epoch [8/10], Step [40/129], Loss: 0.8035\n",
            "Epoch [8/10], Step [60/129], Loss: 0.7834\n",
            "Epoch [8/10], Step [80/129], Loss: 0.7777\n",
            "Epoch [8/10], Step [100/129], Loss: 0.7776\n",
            "Epoch [8/10], Step [120/129], Loss: 0.7911\n",
            "Epoch 8 completed in 40.47 seconds\n",
            "Epoch [9/10], Step [20/129], Loss: 0.7170\n",
            "Epoch [9/10], Step [40/129], Loss: 0.6956\n",
            "Epoch [9/10], Step [60/129], Loss: 0.7152\n",
            "Epoch [9/10], Step [80/129], Loss: 0.7355\n",
            "Epoch [9/10], Step [100/129], Loss: 0.8031\n",
            "Epoch [9/10], Step [120/129], Loss: 0.8398\n",
            "Epoch 9 completed in 40.10 seconds\n",
            "Epoch [10/10], Step [20/129], Loss: 0.6249\n",
            "Epoch [10/10], Step [40/129], Loss: 0.6342\n",
            "Epoch [10/10], Step [60/129], Loss: 0.6247\n",
            "Epoch [10/10], Step [80/129], Loss: 0.6060\n",
            "Epoch [10/10], Step [100/129], Loss: 0.6256\n",
            "Epoch [10/10], Step [120/129], Loss: 0.6164\n",
            "Epoch 10 completed in 40.52 seconds\n"
          ]
        }
      ],
      "source": [
        "# Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start time of the epoch\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i + 1) % 20 == 0:  # Print every 20 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss / 20:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Calculate and print the epoch duration\n",
        "    end_time = time.time()\n",
        "    epoch_duration = end_time - start_time\n",
        "    print(f'Epoch {epoch + 1} completed in {epoch_duration:.2f} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTkK6BspSV_Z",
        "outputId": "597a0a79-edf8-40f3-bdad-edaab38efffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 70.082564351627%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
